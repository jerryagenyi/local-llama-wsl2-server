# Health check endpoint for Nginx
server {
    listen 80;
    server_name _;
    location = /health {
        return 200 'OK';
        add_header Content-Type text/plain;
    }
}
# default.conf
# Nginx reverse proxy config for Ollama API and n8n webhooks


# Upstream for n8n
upstream n8n_backend {
    server n8n:5678;
}

# n8n UI (n8n.jerryagenyi.xyz)
server {
    listen 80;
    server_name n8n.jerryagenyi.xyz;

    location / {
        proxy_pass http://n8n_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}

# n8n Webhooks (webhooks.jerryagenyi.xyz)
server {
    listen 80;
    server_name webhooks.jerryagenyi.xyz;

    location / {
        proxy_pass http://n8n_backend;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_buffering off;
        proxy_read_timeout 300s;
        proxy_send_timeout 300s;
        proxy_connect_timeout 300s;
    }
}

# ... (previous n8n and webhook blocks) ...

# Ollama and LiteLLM API via llm.jerryagenyi.xyz
upstream litellm_backend {
    server litellm:4000;
}
upstream ollama_backend {
    server host.docker.internal:11434;
}

server {
    listen 80;
    server_name llm.jerryagenyi.xyz;

    # Health check endpoint
    location = /health {
        return 200 'OK';
        add_header Content-Type text/plain;
    }

    # Health/info root endpoint
    location = / {
        return 200 "LLM Nginx Proxy is running.";
        add_header Content-Type text/plain;
    }

    # API proxy for LiteLLM
    location /api/litellm/ {
        auth_basic "Restricted LiteLLM API";
        auth_basic_user_file /etc/nginx/.htpasswd;
        proxy_pass http://litellm_backend/api/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_buffering off;
        proxy_read_timeout 300s;
        proxy_send_timeout 300s;
        proxy_connect_timeout 300s;
        # Pass LITELLM_MASTER_KEY as Authorization header
        proxy_set_header Authorization "Bearer sk-dtOcy2cRauc03Oe8W/HpJYfQiHo8hyAKGw6o22+eLc3VbGH256cIghG4t58BYMb"; # Also in docker compose file, so if you change here, change there too. 
    }

    # API proxy for Ollama
    location /api/ollama/ {
        auth_basic "Restricted Ollama API";
        auth_basic_user_file /etc/nginx/.htpasswd;
        proxy_pass http://ollama_backend/api/;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_buffering off;
        proxy_read_timeout 300s;
        proxy_send_timeout 300s;
        proxy_connect_timeout 300s;
    }
}