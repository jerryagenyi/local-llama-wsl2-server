# Nginx reverse proxy config for Ollama API
# See guide for full configuration and endpoint details

events { # This line should now be the first active line, or a comment above it
    worker_connections 1024;
    multi_accept on;
}

http {
    include       mime.types;
    default_type  application/octet-stream;
    sendfile        on;
    keepalive_timeout  65;

    # Upstream to native Windows Ollama server
    upstream ollama_backend {
        server host.docker.internal:11434;
    }

    server {
        listen 80;
        server_name localhost wsl2-w11.jerryagenyi.xyz;

        # Root endpoint for health/info
        location / {
            return 200 "Ollama Nginx Proxy is running.";
        }

        # Proxy all /api/ requests to Ollama backend
        location /api/ {
            proxy_pass http://ollama_backend:11434/api/; # Keep this line as it was
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_buffering off;
            proxy_read_timeout 300s;
            proxy_send_timeout 300s;
            proxy_connect_timeout 300s;
        }
    }
}