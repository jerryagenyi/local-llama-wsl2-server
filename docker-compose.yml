services:
  n8n:
    image: n8nio/n8n:latest
    container_name: n8n-temp
    user: "node"
    ports:
      - "5678:5678"
    environment:
      - N8N_HOST=0.0.0.0
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - N8N_EDITOR_BASE_URL=https://n8n.jerryagenyi.xyz
      - WEBHOOK_URL=https://n8n.jerryagenyi.xyz
      - NODE_ENV=production
      - N8N_ENCRYPTION_KEY=${N8N_ENCRYPTION_KEY}
      - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true
    volumes:
      - n8n_data:/home/node/.n8n
    networks:
      - tunnel-network
    restart: unless-stopped

  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm-api
    ports:
      - "4000:4000"
    environment:
      - PORT=4000
      - HOST=0.0.0.0
      - OLLAMA_API_BASE=http://host.docker.internal:11434
      - LITELLM_API_KEY=${LITELLM_API_KEY}
      - DEBUG=true
      - LITELLM_CONFIG=/app/config.yaml
    volumes:
      - ./config/litellm/config.yaml:/app/config.yaml:ro
      - ./config/litellm/config.yaml:/app/proxy_server_config.yaml:ro
    command: --config /app/config.yaml --host 0.0.0.0
    networks:
      - tunnel-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: cloudflared-tunnel
    command: tunnel --no-autoupdate run --token ${CLOUDFLARE_TUNNEL_TOKEN}
    networks:
      - tunnel-network
    restart: unless-stopped
    depends_on:
      - litellm

  flowise:
    image: flowiseai/flowise:latest
    container_name: flowise
    ports:
      - "3000:3000"
    volumes:
      - flowise_data:/root/.flowise
    environment:
      - PORT=3000
    restart: unless-stopped
    networks:
      - tunnel-network

networks:
  tunnel-network:
    driver: bridge

volumes:
  n8n_data:
  flowise_data: