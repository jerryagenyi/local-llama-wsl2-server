COMPOSE_PROJECT_NAME=local-llama-wsl2-server
DOCKER_BUILDKIT=1

HOST_PORT=8080
INTERNAL_PORT=11434
NGINX_PORT=80
EXTERNAL_NGINX_PORT=8080
ALLOWED_ORIGINS=https://www.jerryagenyi.xyz, https://llm.jerryagenyi.xyz, https://n8n.jerryagenyi.xyz

CLOUDFLARE_TUNNEL_TOKEN=eyJhIjoiYjVkOTg3Y2QxNDVmMjRiNDE0NjI2YjI1MWIxMzQ5NzIiLCJ0IjoiMTZiYWFmYjMtNDljMS00OWM5LWFlNzctMjdkYzUwYjE5YjNhIiwicyI6Ik1tWTFNelV6TVdZdFpqVTVNaTAwT1RjNExUazBabVV0TmpFeVlqVmtOek14T1RJMSJ9
TUNNEL_NAME=desktop-home-lab-tunnel
CLOUDFLARE_ACCOUNT_ID=b5d987cd145f24b414626b251b134972

API_KEY=cd3184b0b49b4c57b4c9fe5b88816f748ca1ab903870e6b33c7ce4a94260733a
BASIC_AUTH_USER=admin
BASIC_AUTH_PASS='admin:$apr1$UzN7IM2z$Kj04zZAt7LhWu1id0Q4GY0'

MODELS_PATH=/home/jerryagenyi/llama-server/models
CONFIG_PATH=/home/jerryagenyi/llama-server/config
LOGS_PATH=/home/jerryagenyi/llama-server/logs

